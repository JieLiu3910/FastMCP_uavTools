import sys
import os
from PIL import Image
import torch
import time
import json
import numpy as np
from typing import List, Literal, Optional,Dict
from datetime import datetime
from transformers import CLIPModel, AutoImageProcessor
from pprint import pprint
import torchvision.transforms as transforms

from pymilvus import connections, Collection, utility  # Milvus ç›¸å…³å¯¼å…¥
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from utils.mae_embedding_basic import load_model, InternVisionConfig
from config_manager import load_config


def search_image_from_milvus(query_image: str, query_type:Literal["history", "target"], config_file: Dict = None)->List[Dict]:
    """
    æœç´¢ä¸è¾“å…¥å›¾åƒåŒ¹é…çš„å†å²å›¾åƒ

    Args:
        query_image: éœ€è¦æŸ¥è¯¢çš„å›¾åƒdirectory
        configs: é…ç½®å­—å…¸

    Returns:
        parsed_results: æœç´¢ç»“æœ
            - id: å›¾åƒ ID
            - distance: å‘é‡ç›¸ä¼¼åº¦ï¼ˆè·ç¦»ï¼‰ï¼Œè¶Šå¤§è¡¨æ˜å›¾åƒè¶Šç›¸ä¼¼
            - metadata: å…ƒæ•°æ®
    """
    configs = load_config(config_file)

    device = "cuda" if torch.cuda.is_available() else "cpu"

    # åŠ è½½ MAE æ¨¡å‹
    mae_model_path = configs.get("mae_model_path")
    model = load_model(mae_model_path, device=device)

    # model = model.to(torch.bfloat16)  # ä½¿ç”¨ bfloat16 ç²¾åº¦
    model.eval()

    # Milvus è¿æ¥
    try:
        connections.connect(
            host=configs["milvus"]["host"], port=configs["milvus"]["port"]
        )
        print("æˆåŠŸè¿æ¥åˆ° Milvus")
    except Exception as e:
        print(f"è¿æ¥ Milvus å¤±è´¥: {e}")
        return []

    # æ ¹æ®ä¸åŒæœç´¢ç±»å‹æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
    if query_type == "history":
        collection_name = configs.get("milvus")["collections"]["history"]
        if not utility.has_collection(collection_name):
            print(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
            return []
        
        search_configs = configs.get("history_search_params")
        if not search_configs:
            raise KeyError("åœ¨ config.yaml ä¸­æœªæ‰¾åˆ° 'history_search_params' é…ç½®")

    elif query_type == "target":
        collection_name = configs.get("milvus")["collections"]["target"]
        if not utility.has_collection(collection_name):
            print(f"é›†åˆ {collection_name} ä¸å­˜åœ¨")
            return []
        
        search_configs = configs.get("target_search_params")
        if not search_configs:
            raise KeyError("åœ¨ config.yaml ä¸­æœªæ‰¾åˆ° 'history_search_params' é…ç½®")

    # è·å–é›†åˆ
    collection = Collection(name=collection_name)
    collection.load()
    print(f"æˆåŠŸåŠ è½½é›†åˆ {collection_name}")

    # è·å–å‘é‡æœç´¢å‚æ•°
    search_params = {
        "metric_type": search_configs["metric_type"],
        "radius": search_configs["radius"],
        "range_filter": search_configs["range_filter"],
        "params": {"nprobe": search_configs["nprobe"]},
    }


    # -------      åƒæ²³å¤§æ¨¡å‹ MAEæ¨¡å‹ --------------

    #  å®šä¹‰å›¾åƒé¢„å¤„ç†è½¬æ¢å™¨ï¼Œæ ¹æ® embedding_test.py ä¸­çš„ç¤ºä¾‹ï¼Œä½¿ç”¨ç‰¹å®šçš„å‡å€¼å’Œæ ‡å‡†å·®
    mean = [86.82476806640625, 92.53337097167969, 89.27667236328125]
    std = [106.50431060791016, 109.83255767822266, 116.78082275390625]
    
    transform = transforms.Compose([
        transforms.Resize((448, 448)),
        transforms.ToTensor(),
        transforms.Lambda(lambda x: x * 255),  # è½¬æ¢å› 0-255 èŒƒå›´
        transforms.Normalize(mean=mean, std=std)
    ])
    
    # å¤„ç†å›¾ç‰‡ç”Ÿæˆå‘é‡
    start = time.time()
    with open(query_image, "rb") as f:
        query_image_data = Image.open(f).convert("RGB").copy()
    with torch.no_grad():
        # åº”ç”¨å›¾åƒé¢„å¤„ç†
        img_tensor = transform(query_image_data).unsqueeze(0).to(device)
        
        # ä½¿ç”¨ MAE æ¨¡å‹ç”Ÿæˆå‘é‡
        feats = model(img_tensor)  # shape [1, 1, 3200]
        
        # æå–å‘é‡å¹¶è¿›è¡Œ L2 å½’ä¸€åŒ–
        feats = feats.squeeze(1)  # shape [1, 3200]
        feats = torch.nn.functional.normalize(feats, p=2, dim=-1)  # ä¸º COSINE åš L2 å½’ä¸€åŒ–
        query_vector = feats[0].detach().cpu().numpy().astype(np.float32)

    # æ‰§è¡Œå‘é‡æœç´¢ï¼Œä½¿ç”¨ COSINE åº¦é‡ï¼ŒMilvus ä¼šè¿”å›ä¸æŸ¥è¯¢å‘é‡ç›¸ä¼¼åº¦åœ¨ (0.7, 1.0] åŒºé—´å†…çš„å‘é‡ï¼Œå¹¶åœ¨ IVF ç±»ç´¢å¼•ä¸‹ä¼šæœç´¢ 10 ä¸ªèšç±»ä¸­å¿ƒã€‚
    # æœç´¢ Top 10 ç›¸ä¼¼å‘é‡
    results = collection.search(
        data=[query_vector],
        anns_field="vector",
        param=search_params,
        limit=search_configs["limit"],
        output_fields=["id", "metadata"],  # è¿”å› id å’Œ metadata å­—æ®µ
    )

    print(f"ç›®æ ‡å›¾åƒæ£€ç´¢è€—æ—¶: {time.time() - start:.2f} ç§’")

    # è§£ææœç´¢ç»“æœ
    parsed_results = []
    for hits in results:
        for hit in hits:
            result_item = {
                "id": hit.entity.get("id"),
                "distance": hit.distance,
            }

            # è§£æ metadata JSON å­—æ®µ
            metadata_str = hit.entity.get("metadata")
            if metadata_str:
                try:
                    metadata = json.loads(metadata_str)
                    result_item.update(metadata)
                except json.JSONDecodeError:
                    print(f"è§£æ metadata å¤±è´¥: {metadata_str}")

            parsed_results.append(result_item)

    return parsed_results


if __name__ == "__main__":

    # æµ‹è¯•MySQLå†å²å›¾åƒæœç´¢
    print("ğŸ’¯ ===   æµ‹è¯•MySQLå†å²å›¾åƒæœç´¢  ===")
    # ä¸ºäº†èƒ½å¤Ÿç‹¬ç«‹è¿è¡Œï¼Œè¿™é‡Œæˆ‘ä»¬åŠ è½½é…ç½®
    configs = load_config()
    image_file = "/mnt/ht3_nas/group/lj/code/FastMCP_uavTools/data/fleet_999/images/999_01.jpg"
    results =  milvus_search_image(
        query_image=image_file,
        query_type="history"
    )

    print("ğŸ“Š ===  MySQLå†å²å›¾åƒæœç´¢ç»“æœ === ")
    pprint(results)
