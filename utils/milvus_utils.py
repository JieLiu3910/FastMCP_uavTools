import os
from pymilvus import connections, Collection
import pandas as pd
import json
from datetime import datetime
from typing import List, Dict, Any, Optional
import pymysql
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from config_manager import load_config

ROOT_DIR = Path(__file__).parent.parent


def expand_metadata_to_columns(data: List[Dict[str, Any]]) -> pd.DataFrame:
    """
    å°† metadata å­—æ®µå±•å¼€ä¸ºç‹¬ç«‹çš„åˆ—

    Args:
        data: Milvus æŸ¥è¯¢ç»“æœåˆ—è¡¨ï¼Œæ¯æ¡è®°å½•åŒ…å« id å’Œ metadata

    Returns:
        pd.DataFrame: å±•å¼€åçš„ DataFrameï¼Œmetadata ä¸­çš„æ¯ä¸ªé”®éƒ½æˆä¸ºç‹¬ç«‹çš„åˆ—

    Example:
        è¾“å…¥: [{"id": "001", "metadata": '{"lat": 1.0, "lon": 2.0}'}]
        è¾“å‡º: DataFrame with columns: id, lat, lon
    """

    if not data:
        return pd.DataFrame()

    expanded_data = []

    for record in data:
        # åˆ›å»ºæ–°è®°å½•ï¼Œä» id å¼€å§‹
        expanded_record = {"id": record.get("id")}

        # è§£æ metadata JSON å­—ç¬¦ä¸²
        metadata_str = record.get("metadata", "{}")
        try:
            metadata_dict = json.loads(metadata_str)
            # å°† metadata ä¸­çš„æ‰€æœ‰é”®å€¼å¯¹æ·»åŠ åˆ°è®°å½•ä¸­
            expanded_record.update(metadata_dict)
        except json.JSONDecodeError as e:
            print(f"âš ï¸  è­¦å‘Š: è®°å½• {record.get('id')} çš„ metadata è§£æå¤±è´¥: {e}")
            # å¦‚æœè§£æå¤±è´¥ï¼Œä¿ç•™åŸå§‹ metadata å­—ç¬¦ä¸²
            expanded_record["metadata"] = metadata_str

        expanded_data.append(expanded_record)

    # è½¬æ¢ä¸º DataFrame
    df = pd.DataFrame(expanded_data)

    return df


def export_to_csv(
    collection_name: str = "images_vector_target",
    output_file: Optional[str] = None,
    batch_size: int = 1000,
    expand_metadata: bool = True,
    host: str = "localhost",
    port: str = "19530",
) -> str:
    """
    ä» Milvus å¯¼å‡ºæ•°æ®åˆ° CSV æ–‡ä»¶

    Args:
        collection_name: Milvus é›†åˆåç§°    [images_vector_history,images_vector_target]
        output_file: è¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„æ–‡ä»¶åï¼‰
        batch_size: æ¯æ‰¹æ¬¡æŸ¥è¯¢çš„æ•°æ®é‡
        expand_metadata: æ˜¯å¦å°† metadata å±•å¼€ä¸ºç‹¬ç«‹çš„åˆ—
        host: Milvus æœåŠ¡å™¨åœ°å€
        port: Milvus æœåŠ¡å™¨ç«¯å£

    Returns:
        str: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„

    Example:
        >>> export_to_csv("images_vector_history", expand_metadata=True)
        'âœ… å·²ä¿å­˜åˆ°: exported_data_history_20251004_212530.csv'
    """

    print(f"\n{'='*60}")
    print(f"ğŸ“¦ å¼€å§‹ä» Milvus å¯¼å‡ºæ•°æ®åˆ° CSV")
    print(f"{'='*60}")

    # è¿æ¥ Milvus
    try:
        connections.connect("default", host=host, port=port)
        print(f"âœ… æˆåŠŸè¿æ¥åˆ° Milvus ({host}:{port})")
    except Exception as e:
        print(f"âŒ è¿æ¥å¤±è´¥: {e}")
        return None

    # åŠ è½½é›†åˆ
    try:
        collection = Collection(collection_name)
        collection.load()
        print(f"âœ… å·²åŠ è½½é›†åˆ: {collection_name}")
    except Exception as e:
        print(f"âŒ åŠ è½½é›†åˆå¤±è´¥: {e}")
        return None

    print(f"ğŸ“Š é›†åˆè®°å½•æ•°: {collection.num_entities:,}")

    # åˆ†æ‰¹æŸ¥è¯¢æ•°æ®
    offset = 0
    all_data = []

    print(f"\nğŸ”„ å¼€å§‹æŸ¥è¯¢æ•°æ® (æ¯æ‰¹ {batch_size:,} æ¡)...")

    while True:
        try:
            res = collection.query(
                expr='id != ""',  # VARCHAR ç±»å‹ä¸»é”®
                output_fields=["id", "metadata"],  # ä¸å¯¼å‡º vector å­—æ®µ
                limit=batch_size,
                offset=offset,
            )
        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
            break

        if not res:
            print(f"âœ… æ‰¹æ¬¡ {offset // batch_size + 1}: æ— æ›´å¤šæ•°æ®")
            break

        print(f"âœ… æ‰¹æ¬¡ {offset // batch_size + 1}: å·²è·å– {len(res):,} æ¡è®°å½•")
        all_data.extend(res)
        offset += batch_size

        if len(res) < batch_size:
            break

    print(f"\nğŸ“¦ æ€»å…±æŸ¥è¯¢åˆ° {len(all_data):,} æ¡è®°å½•")

    if not all_data:
        print("âš ï¸  æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return None

    # å¤„ç†æ•°æ®
    if expand_metadata:
        print("\nğŸ”„ æ­£åœ¨å±•å¼€ metadata å­—æ®µ...")
        df = expand_metadata_to_columns(all_data)
        print(f"âœ… metadata å·²å±•å¼€ä¸º {len(df.columns) - 1} ä¸ªç‹¬ç«‹åˆ—")
        print(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
    else:
        df = pd.DataFrame(all_data)
        print(f"ğŸ“‹ ä¿æŒåŸå§‹æ ¼å¼ï¼Œåˆ—å: {list(df.columns)}")

    # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = os.path.join(ROOT_DIR, "data/object_milvus_data", f"exported_{collection_name}_{timestamp}.csv")

    # ä¿å­˜ä¸º CSV
    print(f"\nğŸ“„ æ­£åœ¨ä¿å­˜ä¸º CSV æ ¼å¼...")
    df.to_csv(output_file, index=False, encoding="utf-8-sig")

    print(f"âœ… CSV æ–‡ä»¶å·²ä¿å­˜åˆ°: {output_file}")
    print(f"ğŸ“Š CSV æ–‡ä»¶: {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—")

    return output_file


def import_data2mysql(
    csv_file: str,
    table_name: str,
    database: Optional[str] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    user: Optional[str] = None,
    password: Optional[str] = None,
    if_exists: str = "append",
    batch_size: int = 1000,
) -> bool:

    """
    å°†CSVæ–‡ä»¶æ•°æ®å¯¼å…¥åˆ°MySQLæ•°æ®åº“
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
        - è‡ªåŠ¨æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è‡ªåŠ¨åˆ›å»º
        - æ ¹æ®CSVæ•°æ®è‡ªåŠ¨æ¨æ–­å¹¶åˆ›å»ºè¡¨ç»“æ„
        - æ”¯æŒæ‰¹é‡æ’å…¥ï¼Œæé«˜å¯¼å…¥æ•ˆç‡
        - æ”¯æŒäº‹åŠ¡å›æ»šï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
    
    Args:
        csv_file: CSVæ–‡ä»¶è·¯å¾„
        table_name: ç›®æ ‡è¡¨å
        database: æ•°æ®åº“åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            æ³¨æ„ï¼šå¦‚æœæŒ‡å®šçš„æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå‡½æ•°ä¼šè‡ªåŠ¨åˆ›å»º
        host: MySQLæœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        port: MySQLæœåŠ¡å™¨ç«¯å£ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        user: MySQLç”¨æˆ·åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        password: MySQLå¯†ç ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        if_exists: è¡¨å­˜åœ¨æ—¶çš„å¤„ç†æ–¹å¼
            - 'fail': å¦‚æœè¡¨å­˜åœ¨åˆ™æŠ¥é”™
            - 'replace': åˆ é™¤åŸè¡¨å¹¶åˆ›å»ºæ–°è¡¨
            - 'append': è¿½åŠ æ•°æ®åˆ°ç°æœ‰è¡¨ï¼ˆé»˜è®¤ï¼‰
        batch_size: æ‰¹é‡æ’å…¥çš„è®°å½•æ•°
    
    Returns:
        bool: å¯¼å…¥æ˜¯å¦æˆåŠŸ
        
    Example:
        >>> # å¯¼å…¥åˆ°æ–°æ•°æ®åº“ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
        >>> import_data2mysql(
        ...     csv_file="exported_images_vector_history_20251005_090541.csv",
        ...     table_name="images_history",
        ...     database="new_database",  # å¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
        ...     if_exists="replace"
        ... )
        True
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ å¼€å§‹å¯¼å…¥CSVæ•°æ®åˆ°MySQLæ•°æ®åº“")
    print(f"{'='*60}")
    
    # åŠ è½½é…ç½®
    try:
        config = load_config()
        milvus_config = config.get("milvus", {})
        mysql_config = config.get("mysql_image", {})
        
        # ä½¿ç”¨æä¾›çš„å‚æ•°æˆ–ä»é…ç½®æ–‡ä»¶è¯»å–
        db_host = host or mysql_config.get("host", "localhost")
        db_port = port or mysql_config.get("port", 3306)
        db_user = user or mysql_config.get("user", "root")
        db_password = password or mysql_config.get("password", "123456")
        db_name = database or mysql_config.get("database", "Object_detection_db")
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        return False
    
    # è¯»å–CSVæ–‡ä»¶
    try:
        print(f"\nğŸ“‚ æ­£åœ¨è¯»å–CSVæ–‡ä»¶: {csv_file}")
        df = pd.read_csv(csv_file, encoding="utf-8-sig")
        print(f"âœ… æˆåŠŸè¯»å– {len(df):,} è¡Œ Ã— {len(df.columns)} åˆ—æ•°æ®")
        print(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
    except Exception as e:
        print(f"âŒ è¯»å–CSVæ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    if df.empty:
        print("âš ï¸  CSVæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ•°æ®å¯å¯¼å…¥")
        return False
    
    # ç¬¬ä¸€æ­¥ï¼šè¿æ¥MySQLæœåŠ¡å™¨ï¼ˆä¸æŒ‡å®šæ•°æ®åº“ï¼‰æ£€æŸ¥å¹¶åˆ›å»ºæ•°æ®åº“
    connection = None
    try:
        print(f"\nğŸ”— æ­£åœ¨è¿æ¥MySQLæœåŠ¡å™¨...")
        connection = pymysql.connect(
            host=db_host,
            port=db_port,
            user=db_user,
            password=db_password,
            charset="utf8mb4",
            autocommit=False,
        )
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨ ({db_host}:{db_port})")
        
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
        cursor = connection.cursor()
        cursor.execute("SHOW DATABASES")
        existing_databases = [db[0] for db in cursor.fetchall()]
        
        if db_name not in existing_databases:
            print(f"\nâš ï¸  æ•°æ®åº“ '{db_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            cursor.execute(f"CREATE DATABASE `{db_name}` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
            connection.commit()
            print(f"âœ… æ•°æ®åº“ '{db_name}' åˆ›å»ºæˆåŠŸ")
        else:
            print(f"âœ… æ•°æ®åº“ '{db_name}' å·²å­˜åœ¨")
        
        # åˆ‡æ¢åˆ°ç›®æ ‡æ•°æ®åº“
        cursor.execute(f"USE `{db_name}`")
        print(f"âœ… å·²åˆ‡æ¢åˆ°æ•°æ®åº“ '{db_name}'")
        
    except pymysql.Error as e:
        print(f"âŒ è¿æ¥MySQLæˆ–åˆ›å»ºæ•°æ®åº“å¤±è´¥: {e}")
        if connection:
            connection.close()
        return False
    
    # ç¬¬äºŒæ­¥ï¼šåœ¨ç›®æ ‡æ•°æ®åº“ä¸­åˆ›å»ºè¡¨å¹¶å¯¼å…¥æ•°æ®
    try:
        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
        cursor.execute(f"SHOW TABLES LIKE '{table_name}'")
        table_exists = cursor.fetchone() is not None
        
        if table_exists:
            if if_exists == "fail":
                print(f"âŒ è¡¨ {table_name} å·²å­˜åœ¨ï¼Œä¸” if_exists='fail'")
                return False
            elif if_exists == "replace":
                print(f"âš ï¸  è¡¨ {table_name} å·²å­˜åœ¨ï¼Œæ­£åœ¨åˆ é™¤...")
                cursor.execute(f"DROP TABLE `{table_name}`")
                print(f"âœ… å·²åˆ é™¤è¡¨ {table_name}")
                table_exists = False
            elif if_exists == "append":
                print(f"â„¹ï¸  è¡¨ {table_name} å·²å­˜åœ¨ï¼Œå°†è¿½åŠ æ•°æ®")
        
        # åˆ›å»ºè¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if not table_exists:
            print(f"\nğŸ”¨ æ­£åœ¨åˆ›å»ºè¡¨ {table_name}...")
            
            # æ¨æ–­å­—æ®µç±»å‹
            column_definitions = []
            for col_name in df.columns:
                dtype = df[col_name].dtype
                
                # æ ¹æ®pandasæ•°æ®ç±»å‹æ˜ å°„åˆ°MySQLç±»å‹
                if col_name == "id":
                    # idå­—æ®µè®¾ç½®ä¸ºä¸»é”®
                    mysql_type = "VARCHAR(255) PRIMARY KEY"
                elif pd.api.types.is_integer_dtype(dtype):
                    mysql_type = "BIGINT"
                elif pd.api.types.is_float_dtype(dtype):
                    mysql_type = "DOUBLE"
                elif pd.api.types.is_bool_dtype(dtype):
                    mysql_type = "BOOLEAN"
                elif pd.api.types.is_datetime64_any_dtype(dtype):
                    mysql_type = "DATETIME"
                else:
                    # å­—ç¬¦ä¸²ç±»å‹ï¼Œæ£€æŸ¥æœ€å¤§é•¿åº¦
                    max_length = df[col_name].astype(str).str.len().max()
                    if pd.isna(max_length) or max_length == 0:
                        max_length = 255
                    elif max_length > 65535:
                        mysql_type = "TEXT"
                    else:
                        mysql_type = f"VARCHAR({min(int(max_length * 1.5), 65535)})"
                
                column_definitions.append(f"`{col_name}` {mysql_type}")
            
            create_table_sql = f"""
            CREATE TABLE `{table_name}` (
                {', '.join(column_definitions)}
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
            """
            
            cursor.execute(create_table_sql)
            print(f"âœ… è¡¨ {table_name} åˆ›å»ºæˆåŠŸ")
            print(f"ğŸ“‹ å­—æ®µå®šä¹‰:\n{chr(10).join(f'  - {defn}' for defn in column_definitions)}")
        
        # æ‰¹é‡æ’å…¥æ•°æ®
        print(f"\nğŸ“¤ æ­£åœ¨æ’å…¥æ•°æ® (æ¯æ‰¹ {batch_size:,} æ¡)...")
        
        # æ›¿æ¢NaNå€¼ä¸ºNone
        df = df.where(pd.notnull(df), None)
        
        total_rows = len(df)
        inserted_rows = 0
        skipped_rows = 0
        
        for i in range(0, total_rows, batch_size):
            batch_df = df.iloc[i:i+batch_size]
            
            # æ„å»ºæ‰¹é‡æ’å…¥SQL
            columns = ", ".join([f"`{col}`" for col in df.columns])
            placeholders = ", ".join(["%s"] * len(df.columns))
            
            # æ ¹æ®if_existså‚æ•°å†³å®šä½¿ç”¨INSERTè¿˜æ˜¯INSERT IGNORE
            if if_exists == "append":
                # è¿½åŠ æ¨¡å¼ä½¿ç”¨INSERT IGNORE,é‡åˆ°é‡å¤ä¸»é”®æ—¶è·³è¿‡
                insert_sql = f"INSERT IGNORE INTO `{table_name}` ({columns}) VALUES ({placeholders})"
            else:
                insert_sql = f"INSERT INTO `{table_name}` ({columns}) VALUES ({placeholders})"
            
            # å‡†å¤‡æ•°æ®
            values = [tuple(row) for row in batch_df.values]
            
            # æ‰§è¡Œæ‰¹é‡æ’å…¥
            cursor.executemany(insert_sql, values)
            
            # è·å–å®é™…æ’å…¥çš„è¡Œæ•°
            actual_inserted = cursor.rowcount
            batch_skipped = len(batch_df) - actual_inserted
            
            connection.commit()
            
            inserted_rows += actual_inserted
            skipped_rows += batch_skipped
            
            if batch_skipped > 0:
                print(f"âœ… æ‰¹æ¬¡ {i // batch_size + 1}: å·²æ’å…¥ {actual_inserted:,} æ¡,è·³è¿‡ {batch_skipped:,} æ¡é‡å¤è®°å½• (æ€»è¿›åº¦: {inserted_rows:,}/{total_rows:,})")
            else:
                print(f"âœ… æ‰¹æ¬¡ {i // batch_size + 1}: å·²æ’å…¥ {inserted_rows:,}/{total_rows:,} æ¡è®°å½•")
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ æ•°æ®å¯¼å…¥å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±å¯¼å…¥ {inserted_rows:,} æ¡æ–°è®°å½•åˆ°è¡¨ {table_name}")
        if skipped_rows > 0:
            print(f"âš ï¸  è·³è¿‡ {skipped_rows:,} æ¡é‡å¤è®°å½•ï¼ˆä¸»é”®å·²å­˜åœ¨ï¼‰")
        print(f"{'='*60}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ å¯¼å…¥æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        if connection:
            connection.rollback()
        return False
        
    finally:
        if connection:
            connection.close()
            print(f"ğŸ”Œ å·²å…³é—­æ•°æ®åº“è¿æ¥")


def import_sql_file(
    sql_file: str,
    database: Optional[str] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    user: Optional[str] = None,
    password: Optional[str] = None,
    encoding: str = "utf-8",
) -> bool:
    """
    ä»SQLæ–‡ä»¶å¯¼å…¥æ•°æ®åˆ°MySQLæ•°æ®åº“
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
        - æ”¯æŒè¯»å–å„ç§SQLæ–‡ä»¶ï¼ˆå»ºè¡¨è¯­å¥ã€æ•°æ®å¯¼å…¥ã€å­˜å‚¨è¿‡ç¨‹ç­‰ï¼‰
        - è‡ªåŠ¨å¤„ç†SQLæ³¨é‡Šï¼ˆ-- å’Œ /* */ æ ¼å¼ï¼‰
        - æ™ºèƒ½åˆ†å‰²SQLè¯­å¥ï¼ˆåŸºäºåˆ†å·åˆ†éš”ç¬¦ï¼‰
        - æ”¯æŒå¤šè¡ŒSQLè¯­å¥
        - è‡ªåŠ¨åˆ›å»ºä¸å­˜åœ¨çš„æ•°æ®åº“
        - æ”¯æŒäº‹åŠ¡å¤„ç†å’Œé”™è¯¯å›æ»š
    
    Args:
        sql_file: SQLæ–‡ä»¶è·¯å¾„
        database: ç›®æ ‡æ•°æ®åº“åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
            æ³¨æ„ï¼šå¦‚æœä¸å­˜åœ¨ä¼šè‡ªåŠ¨åˆ›å»º
        host: MySQLæœåŠ¡å™¨åœ°å€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        port: MySQLæœåŠ¡å™¨ç«¯å£ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        user: MySQLç”¨æˆ·åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        password: MySQLå¯†ç ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        encoding: SQLæ–‡ä»¶ç¼–ç æ ¼å¼ï¼ˆé»˜è®¤utf-8ï¼‰
    
    Returns:
        bool: å¯¼å…¥æ˜¯å¦æˆåŠŸ
        
    Example:
        >>> # å¯¼å…¥SQLæ–‡ä»¶åˆ°æŒ‡å®šæ•°æ®åº“
        >>> import_sql_file(
        ...     sql_file="backup_database.sql",
        ...     database="restored_db",
        ... )
        True
        
        >>> # ä½¿ç”¨è‡ªå®šä¹‰è¿æ¥å‚æ•°
        >>> import_sql_file(
        ...     sql_file="data/backup.sql",
        ...     database="my_database",
        ...     host="localhost",
        ...     port=3306,
        ...     encoding="utf-8"
        ... )
        True
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸ“¥ å¼€å§‹ä»SQLæ–‡ä»¶å¯¼å…¥æ•°æ®åˆ°MySQLæ•°æ®åº“")
    print(f"{'='*60}")
    
    # åŠ è½½é…ç½®
    try:
        config = load_config()
        mysql_config = config.get("mysql_image", {})
        
        # ä½¿ç”¨æä¾›çš„å‚æ•°æˆ–ä»é…ç½®æ–‡ä»¶è¯»å–
        db_host = host or mysql_config.get("host", "localhost")
        db_port = port or mysql_config.get("port", 3306)
        db_user = user or mysql_config.get("user", "root")
        db_password = password or mysql_config.get("password", "123456")
        db_name = database or mysql_config.get("database", "Object_detection_db")
        
    except Exception as e:
        print(f"âŒ åŠ è½½é…ç½®å¤±è´¥: {e}")
        return False
    
    # è¯»å–SQLæ–‡ä»¶
    try:
        print(f"\nğŸ“‚ æ­£åœ¨è¯»å–SQLæ–‡ä»¶: {sql_file}")
        with open(sql_file, 'r', encoding=encoding) as f:
            sql_content = f.read()
        
        if not sql_content.strip():
            print("âš ï¸  SQLæ–‡ä»¶ä¸ºç©º")
            return False
            
        print(f"âœ… æˆåŠŸè¯»å–SQLæ–‡ä»¶ ({len(sql_content)} å­—ç¬¦)")
        
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {sql_file}")
        return False
    except UnicodeDecodeError:
        print(f"âŒ æ–‡ä»¶ç¼–ç é”™è¯¯ï¼Œè¯·å°è¯•å…¶ä»–ç¼–ç æ ¼å¼ï¼ˆå¦‚ 'gbk', 'latin1'ï¼‰")
        return False
    except Exception as e:
        print(f"âŒ è¯»å–SQLæ–‡ä»¶å¤±è´¥: {e}")
        return False
    
    # é¢„å¤„ç†SQLå†…å®¹ï¼šç§»é™¤æ³¨é‡Š
    def remove_comments(sql_text: str) -> str:
        """ç§»é™¤SQLæ³¨é‡Š"""
        lines = []
        in_multiline_comment = False
        
        for line in sql_text.split('\n'):
            # å¤„ç†å¤šè¡Œæ³¨é‡Š /* */
            if '/*' in line:
                in_multiline_comment = True
                line = line[:line.index('/*')]
            if '*/' in line:
                in_multiline_comment = False
                line = line[line.index('*/') + 2:]
                
            if in_multiline_comment:
                continue
                
            # å¤„ç†å•è¡Œæ³¨é‡Š --
            if '--' in line:
                line = line[:line.index('--')]
                
            # å¤„ç†å•è¡Œæ³¨é‡Š #
            if '#' in line:
                line = line[:line.index('#')]
                
            line = line.strip()
            if line:
                lines.append(line)
        
        return '\n'.join(lines)
    
    # ç§»é™¤æ³¨é‡Š
    sql_content = remove_comments(sql_content)
    
    # åˆ†å‰²SQLè¯­å¥ï¼ˆåŸºäºåˆ†å·ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨ç®€å•çš„åˆ†å·åˆ†å‰²ï¼Œå¯èƒ½ä¸é€‚ç”¨äºåŒ…å«åˆ†å·çš„å­—ç¬¦ä¸²
    sql_statements = [stmt.strip() for stmt in sql_content.split(';') if stmt.strip()]
    
    print(f"ğŸ“‹ è§£æåˆ° {len(sql_statements)} æ¡SQLè¯­å¥")
    
    # è¿æ¥MySQLæœåŠ¡å™¨
    connection = None
    try:
        print(f"\nğŸ”— æ­£åœ¨è¿æ¥MySQLæœåŠ¡å™¨...")
        connection = pymysql.connect(
            host=db_host,
            port=db_port,
            user=db_user,
            password=db_password,
            charset="utf8mb4",
            autocommit=False,
        )
        print(f"âœ… æˆåŠŸè¿æ¥åˆ°MySQLæœåŠ¡å™¨ ({db_host}:{db_port})")
        
        cursor = connection.cursor()
        
        # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º
        cursor.execute("SHOW DATABASES")
        existing_databases = [db[0] for db in cursor.fetchall()]
        
        if db_name not in existing_databases:
            print(f"\nâš ï¸  æ•°æ®åº“ '{db_name}' ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
            cursor.execute(f"CREATE DATABASE `{db_name}` CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci")
            connection.commit()
            print(f"âœ… æ•°æ®åº“ '{db_name}' åˆ›å»ºæˆåŠŸ")
        else:
            print(f"âœ… æ•°æ®åº“ '{db_name}' å·²å­˜åœ¨")
        
        # åˆ‡æ¢åˆ°ç›®æ ‡æ•°æ®åº“
        cursor.execute(f"USE `{db_name}`")
        print(f"âœ… å·²åˆ‡æ¢åˆ°æ•°æ®åº“ '{db_name}'")
        
    except pymysql.Error as e:
        print(f"âŒ è¿æ¥MySQLå¤±è´¥: {e}")
        if connection:
            connection.close()
        return False
    
    # æ‰§è¡ŒSQLè¯­å¥
    try:
        print(f"\nğŸ“¤ å¼€å§‹æ‰§è¡ŒSQLè¯­å¥...")
        
        executed_count = 0
        failed_count = 0
        
        for i, statement in enumerate(sql_statements, 1):
            # è·³è¿‡ç©ºè¯­å¥å’ŒUSE DATABASEè¯­å¥ï¼ˆå› ä¸ºå·²ç»åˆ‡æ¢äº†ï¼‰
            if not statement or statement.upper().startswith('USE '):
                continue
            
            try:
                cursor.execute(statement)
                executed_count += 1
                
                # æ¯10æ¡è¯­å¥æäº¤ä¸€æ¬¡
                if executed_count % 10 == 0:
                    connection.commit()
                    print(f"âœ… å·²æ‰§è¡Œ {executed_count}/{len(sql_statements)} æ¡è¯­å¥")
                    
            except pymysql.Error as e:
                failed_count += 1
                print(f"âš ï¸  è¯­å¥ {i} æ‰§è¡Œå¤±è´¥: {str(e)[:100]}")
                # æ ¹æ®éœ€è¦å†³å®šæ˜¯å¦ç»§ç»­æ‰§è¡Œ
                # è¿™é‡Œé€‰æ‹©è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
                continue
        
        # æäº¤å‰©ä½™çš„äº‹åŠ¡
        connection.commit()
        
        print(f"\n{'='*60}")
        print(f"ğŸ‰ SQLæ–‡ä»¶å¯¼å…¥å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±æ‰§è¡Œ {executed_count} æ¡è¯­å¥")
        if failed_count > 0:
            print(f"âš ï¸  å¤±è´¥ {failed_count} æ¡è¯­å¥")
        print(f"{'='*60}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æ‰§è¡ŒSQLè¯­å¥æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        if connection:
            connection.rollback()
        return False
        
    finally:
        if connection:
            connection.close()
            print(f"ğŸ”Œ å·²å…³é—­æ•°æ®åº“è¿æ¥")


def expor2csv_and_import2mysql(
    milvus_collection_name: str="images_vector_history",
    mysql_database_name: str="test_db",
    mysql_table_name: str="test_milvus_data",
    expand_metadata: bool=True,
    batch_size: int=1000,
    if_exists: str ="append",
    ):
   
    output_file = export_to_csv(
        collection_name=milvus_collection_name,
        expand_metadata=expand_metadata,
        batch_size=batch_size,
    )

    if output_file:
        print(f"\n{'='*60}")
        print(f"ğŸ‰ å¯¼å‡ºå®Œæˆï¼")
        print(f"ğŸ“ æ–‡ä»¶: {output_file}")
        print(f"{'='*60}")
    else:
        print(f"\n{'='*60}")
        print(f"âŒ å¯¼å‡ºå¤±è´¥")
        print(f"{'='*60}")
        output_file = None
    
    # ========== ç¬¬äºŒæ­¥ï¼šå°†CSVæ•°æ®å¯¼å…¥MySQLï¼ˆå¯é€‰ï¼‰==========
    
    # å¦‚æœéœ€è¦å°†å¯¼å‡ºçš„CSVæ•°æ®å¯¼å…¥åˆ°MySQLï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    if output_file:
        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®åˆ°MySQL")
        print("="*60)
        
        success = import_data2mysql(
            csv_file=output_file,
            table_name=mysql_table_name,  # ç›®æ ‡è¡¨å
            database=mysql_database_name,  # ç›®æ ‡æ•°æ®åº“ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
            # if_exists="replace",  # 'fail'/'replace'/'append'
            batch_size=1000,
        )
        
        if success:
            print(f"\n{'='*60}")
            print(f"ğŸ‰ MySQLå¯¼å…¥å®Œæˆï¼")
            print(f"{'='*60}")
        else:
            print(f"\n{'='*60}")
            print(f"âŒ MySQLå¯¼å…¥å¤±è´¥")
            print(f"{'='*60}")

if __name__ == "__main__":
    
    # å¯¼å‡ºMilvusæ•°æ®åˆ°CSVå¹¶å¯¼å…¥MySQL
    # expor2csv_and_import2mysql(
    #     milvus_collection_name="images_vector_history", 
    #     mysql_table_name="test_milvus_data", 
    #     mysql_database_name="test1",
    # )

    expor2csv_and_import2mysql(
        milvus_collection_name="TW_0829_history", 
        mysql_table_name="history_object_images", 
        mysql_database_name="Object_detection_db",
    )

    expor2csv_and_import2mysql(
        milvus_collection_name="TW_0829_target", 
        mysql_table_name="all_objects_images", 
        mysql_database_name="Object_detection_db",
    )

    # expor2csv_and_import2mysql(
    #     milvus_collection_name="fleet_target", 
    #     mysql_table_name="all_objects_images", 
    #     mysql_database_name="Object_detection_db",
    # )

    # expor2csv_and_import2mysql(
    #     milvus_collection_name="fleet_history", 
    #     mysql_table_name="fleet_history", 
    #     mysql_database_name="Object_detection_db",
    # )


    # å¯¼å…¥SQLæ–‡ä»¶åˆ°MySQL
    # import_sql_file(
    #     sql_file=r"C:\Users\LJ\Desktop\æ¡Œé¢æ–‡ä»¶å¤¹\sqlæ•°æ®\Equipments_db.sql",
    #     database="test2",
    #     host="localhost",
    #     port=3306,
    #     user="root",
    #     password="123456",
    #     encoding="utf-8",
    # )
    